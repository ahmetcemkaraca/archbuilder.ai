# AIService D√∂k√ºmantasyonu

AIService, ArchBuilder.AI'ƒ±n kalbi olan AI i≈üleme ve model y√∂netimi servisidir. Bu servis, Vertex AI ve OpenAI/Azure OpenAI'yi kullanarak mimari layout generation, requirement analysis ve Revit command generation i≈ülemlerini ger√ßekle≈ütirir.

## üìã ƒ∞√ßindekiler

1. [Genel Bakƒ±≈ü](#genel-bakƒ±≈ü)
2. [Mimari Yapƒ±](#mimari-yapƒ±)
3. [Ana Bile≈üenler](#ana-bile≈üenler)
4. [AI Model Y√∂netimi](#ai-model-y√∂netimi)
5. [Prompt Engineering](#prompt-engineering)
6. [Fallback Mekanizmalarƒ±](#fallback-mekanizmalarƒ±)
7. [Performans ve Cache](#performans-ve-cache)
8. [Kullanƒ±m √ñrnekleri](#kullanƒ±m-√∂rnekleri)
9. [Hata Y√∂netimi](#hata-y√∂netimi)

## üîç Genel Bakƒ±≈ü

AIService a≈üaƒüƒ±daki temel i≈ülevleri saƒülar:

### Desteklenen AI Modelleri
- **Vertex AI**: Gemini-2.5-Flash-Lite (karma≈üƒ±k projeler i√ßin)
- **OpenAI/Azure OpenAI**: GPT-4.1 (hƒ±zlƒ± i≈ülemler i√ßin)
- **Otomatik Model Se√ßimi**: Task complexity'e g√∂re en uygun modeli se√ßer

### Ana ƒ∞≈ülevler
- **Layout Generation**: AI destekli mimari layout olu≈üturma
- **Requirement Analysis**: Proje gereksinimlerini analiz etme
- **Site Analysis**: Arsa ko≈üullarƒ±nƒ± deƒüerlendirme
- **Validation**: Building code compliance kontrol√º
- **Optimization**: Layout optimizasyonu
- **Revit Command Generation**: Revit API komutlarƒ± olu≈üturma

## üèóÔ∏è Mimari Yapƒ±

```mermaid
graph TB
    A[AIService] --> B[AIModelSelector]
    A --> C[ArchitecturalPromptEngine]
    A --> D[AIFallbackService]
    A --> E[Cache Layer]
    
    B --> F[Vertex AI Client]
    B --> G[OpenAI/Azure OpenAI Client]
    
    C --> H[Prompt Templates]
    C --> I[RAG Integration]
    
    D --> J[Rule-based Layout]
    D --> K[Template Generation]
```

## üß© Ana Bile≈üenler

### 1. AIModelSelector
Model se√ßimi ve y√ºk dengeleme i≈ülemlerini y√∂netir.

```python
class AIModelSelector:
    async def select_optimal_model(
        self,
        task_type: AITaskType,
        complexity_score: float,
        context_length: int
    ) -> AIModelConfig
```

**√ñzellikler**:
- Task complexity'e g√∂re otomatik model se√ßimi
- Model availability kontrol√º  
- Failover mekanizmasƒ±
- Performance tracking

**Model Se√ßim Kriterleri**:
- **Basit g√∂revler** (complexity < 0.3): OpenAI/Azure OpenAI (GPT-4.1)
- **Orta g√∂revler** (0.3 ‚â§ complexity < 0.7): Vertex AI (Gemini-2.5-Flash-Lite)
- **Karma≈üƒ±k g√∂revler** (complexity ‚â• 0.7): Vertex AI (Gemini-2.5-Flash-Lite)

### 2. ArchitecturalPromptEngine
Yapƒ±landƒ±rƒ±lmƒ±≈ü prompt generation ve RAG entegrasyonu.

```python
class ArchitecturalPromptEngine:
    async def generate_layout_prompt(
        self,
        request: AILayoutRequest,
        rag_context: Optional[str],
        language: str
    ) -> str
```

**√ñzellikler**:
- √áok dilli prompt templateleri
- RAG context integration
- Building code specific prompts
- Structured output formatting

**Prompt Yapƒ±sƒ±**:
```
1. System Context (Mimari tasarƒ±m uzmanƒ± rol√º)
2. Project Requirements (Proje gereksinimleri)
3. RAG Context (ƒ∞lgili y√∂netmelik kurallarƒ±)
4. Task Specification (Spesifik g√∂rev tanƒ±mƒ±)
5. Output Format (JSON yapƒ±landƒ±rmasƒ±)
6. Safety Guidelines (G√ºvenlik kurallarƒ±)
```

### 3. AIFallbackService
AI hata durumlarƒ±nda rule-based fallback saƒülar.

```python
class AIFallbackService:
    async def generate_fallback_layout(
        self,
        request: AILayoutRequest
    ) -> AILayoutResponse
```

**Fallback Senaryolarƒ±**:
- AI model eri≈üim hatasƒ±
- D√º≈ü√ºk confidence score (<0.5)
- Rate limiting
- Timeout durumlarƒ±

**Rule-based Generation**:
- Standart mimari kurallarƒ±
- Building type specific templates
- Minimum code compliance
- Basic space allocation

## ü§ñ AI Model Y√∂netimi

### Model Configuration
```python
@dataclass
class AIModelConfig:
    provider: str  # "vertex_ai" or "github_models"
    model_name: str
    max_tokens: int
    temperature: float
    context_window: int
```

### Provider Implementations

#### Vertex AI Integration
```python
async def _call_vertex_ai(
    self,
    prompt: str,
    model_config: AIModelConfig,
    correlation_id: str
) -> AIResponse
```

**√ñzellikler**:
- Gemini-2.5-Flash-Lite model desteƒüi
- Streaming response desteƒüi
- Token usage tracking
- Error handling ve retry logic

#### GitHub Models Integration
```python
async def _call_github_models(
    self,
    prompt: str,
    model_config: AIModelConfig,
    correlation_id: str
) -> AIResponse
```

**√ñzellikler**:
- GPT-4.1 model desteƒüi
- Faster response times
- Cost optimization
- Rate limiting management

## üìù Prompt Engineering

### Template Sistemi
AIService √ßok dilli prompt template sistemi kullanƒ±r:

```
templates/
‚îú‚îÄ‚îÄ en/
‚îÇ   ‚îú‚îÄ‚îÄ layout_generation.txt
‚îÇ   ‚îú‚îÄ‚îÄ requirement_analysis.txt
‚îÇ   ‚îî‚îÄ‚îÄ validation.txt
‚îú‚îÄ‚îÄ tr/
‚îÇ   ‚îú‚îÄ‚îÄ layout_generation.txt
‚îÇ   ‚îú‚îÄ‚îÄ requirement_analysis.txt
‚îÇ   ‚îî‚îÄ‚îÄ validation.txt
‚îî‚îÄ‚îÄ ...
```

### Prompt Yapƒ±sƒ± √ñrneƒüi

#### Layout Generation Prompt (T√ºrk√ße)
```
Sen uzman bir mimar ve AI destekli tasarƒ±m uzmanƒ±sƒ±n.

PROJE Bƒ∞LGƒ∞LERƒ∞:
- Yapƒ± Tipi: {building_type}
- Toplam Alan: {total_area} m¬≤
- Kat Sayƒ±sƒ±: {floors}
- √ñzel Gereksinimler: {requirements}

Y√ñNETMELƒ∞K KURALLARI:
{rag_context}

G√ñREV:
Verilen gereksinimlere uygun mimari layout olu≈ütur.

√áIKTI FORMATI:
{
  "rooms": [...],
  "circulation": {...},
  "structure": [...],
  "compliance": {...}
}

G√úVENLƒ∞K KURALLARI:
- Yangƒ±n g√ºvenliƒüi kurallarƒ±na uy
- Yapƒ±sal g√ºvenlik saƒüla
- Eri≈üilebilirlik standartlarƒ±nƒ± kar≈üƒ±la
```

### RAG Context Integration
```python
# RAG context'i prompt'a entegre etme
rag_context = await self.rag_service.query_knowledge_base(
    query=f"Building codes for {request.building_type}",
    max_results=5,
    language=request.language
)

prompt = self.prompt_engine.generate_layout_prompt(
    request=request,
    rag_context=rag_context.formatted_content,
    language=request.language
)
```

## üîÑ Fallback Mekanizmalarƒ±

### Cascade Fallback Strategy
```python
async def generate_architectural_layout(
    self,
    request: AILayoutRequest,
    correlation_id: str
) -> AILayoutResponse:
    
    # Primary: AI Model
    try:
        ai_response = await self._process_with_ai(request)
        if ai_response.confidence_score >= 0.5:
            return ai_response
    except Exception:
        logger.warning("AI processing failed, trying fallback")
    
    # Secondary: Rule-based Fallback
    try:
        fallback_response = await self.fallback_service.generate_fallback_layout(request)
        return fallback_response
    except Exception:
        logger.error("All fallback mechanisms failed")
        raise AIServiceException("Layout generation completely failed")
```

### Fallback Quality Indicators
```python
class FallbackQuality(Enum):
    AI_HIGH_CONFIDENCE = "ai_high"      # >0.8 confidence
    AI_MEDIUM_CONFIDENCE = "ai_medium"  # 0.5-0.8 confidence
    AI_LOW_CONFIDENCE = "ai_low"        # <0.5 confidence  
    RULE_BASED = "rule_based"           # Fallback used
    HYBRID = "hybrid"                   # AI + Rules combined
```

## ‚ö° Performans ve Cache

### Multi-layer Caching
```python
# 1. Memory Cache (hƒ±zlƒ± eri≈üim)
self.memory_cache: Dict[str, Any] = {}

# 2. Redis Cache (payla≈üƒ±mlƒ± cache)
self.redis_cache: AsyncCache = AsyncCache()

# 3. Model Response Cache
cache_key = f"ai_response:{prompt_hash}:{model_name}"
```

### Cache Stratejisi
- **Prompt Responses**: 1 saat TTL
- **Model Metadata**: 24 saat TTL
- **Fallback Templates**: 7 g√ºn TTL
- **RAG Context**: 30 dakika TTL

### Performance Tracking
```python
@dataclass
class AIPerformanceMetrics:
    model_used: str
    response_time_ms: int
    token_count: int
    confidence_score: float
    cache_hit: bool
    fallback_used: bool
```

## üí° Kullanƒ±m √ñrnekleri

### Basit Layout Generation
```python
# Layout generation request
request = AILayoutRequest(
    user_input="3 bedroom apartment with modern design",
    project_type="residential",
    building_type="apartment",
    total_area=120.0,
    floors=1,
    language="tr"
)

# Generate layout
response = await ai_service.generate_architectural_layout(
    request, correlation_id="proj_123"
)

# Response i√ßeriƒüi
if response.success:
    print(f"Layout generated with {response.confidence_score} confidence")
    print(f"Rooms: {len(response.layout_data['rooms'])}")
    print(f"Revit commands: {len(response.revit_commands)}")
```

### Requirement Analysis
```python
# Requirement analysis
analysis_request = AILayoutRequest(
    user_input="Hospital building with emergency department",
    building_type="hospital",
    language="en"
)

response = await ai_service.analyze_project_requirements(
    analysis_request, correlation_id="analysis_456"
)

# Extracted requirements
requirements = response.layout_data.get("requirements", [])
regulations = response.layout_data.get("regulations", [])
```

### Site Analysis
```python
# Site conditions analysis
site_request = AILayoutRequest(
    user_input="Analyze site for office building",
    building_type="office",
    site_constraints=["sloped terrain", "north-facing"],
    language="tr"
)

response = await ai_service.analyze_site_conditions(
    site_request, correlation_id="site_789"
)

# Site analysis results
constraints = response.layout_data.get("constraints", [])
recommendations = response.layout_data.get("recommendations", [])
```

## üö® Hata Y√∂netimi

### Exception Hierarchy
```python
AIServiceException
‚îú‚îÄ‚îÄ ModelNotAvailableException
‚îú‚îÄ‚îÄ PromptGenerationException
‚îú‚îÄ‚îÄ ValidationException
‚îú‚îÄ‚îÄ RateLimitException
‚îî‚îÄ‚îÄ FallbackFailedException
```

### Error Handling Strategy
```python
try:
    response = await ai_service.generate_architectural_layout(request)
except ModelNotAvailableException:
    # Switch to alternative model
    response = await ai_service._retry_with_fallback_model(request)
except RateLimitException:
    # Implement exponential backoff
    await asyncio.sleep(calculate_backoff_delay())
    response = await ai_service._retry_request(request)
except ValidationException as e:
    # Log validation errors and use rule-based fallback
    logger.error(f"AI output validation failed: {e}")
    response = await fallback_service.generate_fallback_layout(request)
```

### Monitoring ve Alerting
```python
# Performance monitoring
log_ai_operation(
    operation="layout_generation",
    model_used=response.model_info.model_name,
    input_tokens=response.token_usage.input_tokens,
    output_tokens=response.token_usage.output_tokens,
    response_time_ms=response.processing_time_ms,
    confidence_score=response.confidence_score,
    correlation_id=correlation_id
)

# Alert conditions
if response.confidence_score < 0.3:
    alert_low_confidence(correlation_id, response)
    
if response.processing_time_ms > 30000:  # 30 seconds
    alert_slow_response(correlation_id, response)
```

## üìä Performance Metrikleri

### Target Performance
- **Simple Layout**: <30 seconds
- **Complex Layout**: <5 minutes
- **API Response Time**: <500ms (cached)
- **Model Switching**: <2 seconds
- **Confidence Score**: >0.7 average

### Monitoring Dashboard
```python
{
    "ai_service_metrics": {
        "total_requests": 1247,
        "success_rate": 0.94,
        "average_confidence": 0.78,
        "average_response_time_ms": 12500,
        "cache_hit_rate": 0.23,
        "fallback_usage_rate": 0.06,
        "model_distribution": {
            "vertex_ai": 0.72,
            "github_models": 0.28
        }
    }
}
```

## üîß Configuration

### Environment Variables
```bash
# AI Model Configuration
VERTEX_AI_PROJECT_ID=archbuilder-ai-project
VERTEX_AI_LOCATION=us-central1
GITHUB_MODELS_API_KEY=ghp_xxxxx

# Performance Tuning
AI_CACHE_TTL_SECONDS=3600
AI_REQUEST_TIMEOUT_SECONDS=120
AI_MAX_RETRIES=3
AI_FALLBACK_THRESHOLD=0.5

# Model Selection
DEFAULT_MODEL_PROVIDER=vertex_ai
ENABLE_FALLBACK=true
ENABLE_CACHING=true
```

### Model Limits
```python
MODEL_LIMITS = {
    "vertex_ai": {
        "max_tokens": 8192,
        "requests_per_minute": 60,
        "context_window": 32768
    },
    "github_models": {
        "max_tokens": 4096,
        "requests_per_minute": 180,
        "context_window": 16384
    }
}
```

---

**Bu dok√ºmantasyon AIService'in t√ºm √∂zelliklerini ve kullanƒ±mƒ±nƒ± kapsamaktadƒ±r. Daha detaylƒ± bilgi i√ßin kaynak kodu incelenebilir.**